import cv2
import mediapipe as mp
import time
import math
import sys
import os
import tkinter as tk
from collections import deque, Counter
from PIL import Image, ImageTk

# Matplotlib for the UI graphs
from matplotlib.figure import Figure
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import numpy as np

# Audio Control Libraries (Windows)
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume

# --- 1. GLOBAL CONSTANTS ---
WIN_W = 1280
WIN_H = 720

# --- 2. MEDIAPIPE SETUP ---
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# --- 3. AUDIO CONTROL SETUP (FIXED) ---
volume_interface = None
try:
    # 1. Get the device enumerator directly
    enum = AudioUtilities.GetDeviceEnumerator()
    # 2. Get the default speaker (0=Render, 1=Multimedia)
    device = enum.GetDefaultAudioEndpoint(0, 1)
    # 3. Activate the interface
    interface = device.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
    volume_interface = cast(interface, POINTER(IAudioEndpointVolume))
    print("Audio Driver: Connected successfully.")
except Exception as e:
    print(f"Audio Driver Error: {e}")
    volume_interface = None

# --- 4. HELPER FUNCTIONS ---

def get_mic_volume_percent():
    """Returns current system volume as percentage (0-100)."""
    if volume_interface:
        try:
            current_vol = volume_interface.GetMasterVolumeLevelScalar()
            return int(round(current_vol * 100))
        except: pass
    return 0

def set_mic_volume_percent(target_pct):
    """Sets system volume to target percentage."""
    if volume_interface:
        try:
            # Clamp value between 0.0 and 1.0
            val = max(0.0, min(1.0, target_pct / 100.0))
            volume_interface.SetMasterVolumeLevelScalar(val, None)
        except: pass

def get_mic_is_muted():
    """Returns True if system is muted."""
    if volume_interface:
        try:
            return volume_interface.GetMute() == 1
        except: pass
    return False

def fingers_to_percent(fingers):
    """Maps finger count (0-5) to volume percentage (0-100)."""
    mapping = {
        0: 0,
        1: 20,
        2: 40,
        3: 60,
        4: 80,
        5: 100
    }
    return mapping.get(fingers, 0)

# --- 5. DUMMY VARIABLES ---
mc = None 
child_path = None

class App:
    def __init__(self, stable_frames=6, cam_index=0, win_w=1280, win_h=720):
        self.stable_frames = stable_frames
        self.cam_index = cam_index
        self.win_w = win_w
        self.win_h = win_h

        # 1. Camera
        try: self.cap = cv2.VideoCapture(self.cam_index, cv2.CAP_DSHOW)
        except: self.cap = cv2.VideoCapture(self.cam_index)
        if not self.cap.isOpened(): raise RuntimeError("Cannot open camera.")

        # 2. MediaPipe
        self.hands = mp_hands.Hands(
            static_image_mode=False, model_complexity=1,
            min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=1
        )

        # 3. Logic & State
        self.history = deque(maxlen=self.stable_frames)
        self.current_applied = get_mic_volume_percent()
        self.last_observed = 0
        self.running = True
        self.start_time = time.time()

        # --- UI SETUP ---
        self.root = tk.Tk()
        self.root.title("Infosys_GestureVolume: Finger -> Mic Volume")
        self.root.geometry(f"{WIN_W}x{WIN_H}")
        self.root.configure(bg="#050505")
        self.root.protocol("WM_DELETE_WINDOW", self._on_close)

        # Layout
        self.root.rowconfigure(0, weight=0) # Header
        self.root.rowconfigure(1, weight=1) # Main
        self.root.rowconfigure(2, weight=0) # Footer
        self.root.columnconfigure(0, weight=1)

        # --- HEADER ---
        self.header_frame = tk.Frame(self.root, bg="#111", height=70)
        self.header_frame.grid(row=0, column=0, sticky="ew", padx=0, pady=(0, 5))
        self.header_frame.grid_propagate(False)
        
        self.heading_label = tk.Label(
            self.header_frame, text="Infosys_GestureVolume: Volume Control with Hand Gestures",
            font=("Consolas", 18, "bold"), fg="#00ffcc", bg="#111", anchor="w", padx=20
        )
        self.heading_label.pack(fill=tk.X, pady=(5, 0))
        
        self.sub_label = tk.Label(
            self.header_frame,
            text="Project by BATCH A | SNEHIL GHOSH, GAUTAM N CHIPKAR, AMRUTHA VARSHANI, AYUSH GORGE",
            font=("Consolas", 10), fg="#cccccc", bg="#111", anchor="w", padx=20
        )
        self.sub_label.pack(fill=tk.X, pady=(0, 5))

        # --- MAIN CONTENT ---
        self.main_frame = tk.Frame(self.root, bg="#050505")
        self.main_frame.grid(row=1, column=0, sticky="nsew", padx=10, pady=5)
        self.main_frame.columnconfigure(0, weight=1) # HUD
        self.main_frame.columnconfigure(1, weight=3) # Video
        self.main_frame.rowconfigure(0, weight=1)

        # LEFT PANEL (HUD)
        self.hud_panel = tk.Frame(self.main_frame, bg="#050505")
        self.hud_panel.grid(row=0, column=0, sticky="nsew", padx=(0, 10))
        self.hud_panel.rowconfigure(0, weight=1)
        self.hud_panel.rowconfigure(1, weight=1)

        # --- GRAPH 1: ARC REACTOR (Solid Fill Version) ---
        self.fig_arc = Figure(figsize=(3, 3), dpi=100, facecolor='#050505')
        self.ax_arc = self.fig_arc.add_subplot(111, projection='polar')
        self.ax_arc.set_facecolor('#050505')
        self.ax_arc.grid(False)
        self.ax_arc.set_xticklabels([])
        self.ax_arc.set_yticklabels([])
        self.ax_arc.spines['polar'].set_visible(False)
        
        # Draw Background Track First
        self.ax_arc.bar([0], [2.4], width=2*math.pi, color='#151515', bottom=0.0)
        # Draw Dynamic Bar Second
        self.arc_bar = self.ax_arc.bar([0], [2.4], width=0, color='#00ffff', bottom=0.0)[0]
        
        self.ax_arc.set_ylim(0, 2.5) 
        self.text_vol = self.ax_arc.text(0, 0, "0%", ha='center', va='center', color='white', fontsize=18, fontweight='bold', zorder=10)
        self.text_label = self.ax_arc.text(0, -1.5, "VOLUME", ha='center', va='center', color='black', fontsize=9, fontweight='bold', zorder=10) 
        
        self.canvas_arc = FigureCanvasTkAgg(self.fig_arc, master=self.hud_panel)
        self.canvas_arc.get_tk_widget().grid(row=0, column=0, sticky="nsew")

        # --- GRAPH 2: Z-AXIS PROXIMITY RADAR ---
        self.fig_prox = Figure(figsize=(3, 2), dpi=100, facecolor='#050505')
        self.ax_prox = self.fig_prox.add_subplot(111)
        self.ax_prox.set_facecolor('#0f0f0f')
        
        # Labels and Grid
        self.ax_prox.set_title("Z-AXIS PROXIMITY SENSOR", color='#00ffcc', fontsize=9, pad=10)
        self.ax_prox.set_ylabel("Depth Intensity", color='#888', fontsize=8)
        self.ax_prox.tick_params(colors='#888', labelsize=7)
        self.ax_prox.set_xticks([]) # Hide X-axis ticks (it's a single bar)
        self.ax_prox.grid(True, axis='y', color="#333", linestyle="--", linewidth=0.5)
        
        # The Proximity Bar (Vertical)
        # x=0, height=0 initially, width=0.5
        self.bar_prox = self.ax_prox.bar([0], [0], width=0.4, color='#00ff00', alpha=0.8)[0]
        self.ax_prox.set_ylim(0, 1.0) # Normalized range 0.0 to 1.0
        self.ax_prox.set_xlim(-0.5, 0.5)
        
        # Add a "Warning Line" at 0.8
        self.ax_prox.axhline(0.8, color='#ff3333', linestyle=':', linewidth=1)
        self.ax_prox.text(0.3, 0.82, "CRITICAL", color='#ff3333', fontsize=6)

        self.canvas_prox = FigureCanvasTkAgg(self.fig_prox, master=self.hud_panel)
        self.canvas_prox.get_tk_widget().grid(row=1, column=0, sticky="nsew", pady=10)


        # RIGHT: VIDEO
        self.video_label = tk.Label(self.main_frame, bg="black")
        self.video_label.grid(row=0, column=1, sticky="nsew")

        # --- FOOTER ---
        self.status_label = tk.Label(
            self.root, text="System Ready", bg="#111", fg="#00ff99",
            font=("Consolas", 12), anchor="w", padx=10, pady=5
        )
        self.status_label.grid(row=2, column=0, sticky="ew")

        self.root.bind("<Key>", self._on_keypress)
        self.root.after(10, self._update_frame)

    def _on_keypress(self, event):
        try:
            if hasattr(event, "char") and event.char and event.char.lower() == "q":
                self._on_close()
        except: pass

    def _update_frame(self):
        if not self.running: return

        ret, frame = self.cap.read()
        if not ret:
            self.root.after(50, self._update_frame)
            return

        # 1. Vision Logic
        frame = cv2.flip(frame, 1)
        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        results = None
        try: results = self.hands.process(img_rgb)
        except: pass

        fingers_found = 0
        wrist_z_estimate = 0.0 # Proximity estimate

        if results and results.multi_hand_landmarks:
            hand_landmarks = results.multi_hand_landmarks[0]
            mp_drawing.draw_landmarks(
                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(0,255,255), thickness=2, circle_radius=2),
                mp_drawing.DrawingSpec(color=(255,0,255), thickness=2, circle_radius=2)
            )
            lm = hand_landmarks.landmark
            
            # --- COUNT FINGERS ---
            fingers_found = 0
            tips_pips = [(8,6), (12,10), (16,14), (20,18)]
            for tip, pip in tips_pips:
                try:
                    if lm[tip].y < lm[pip].y: fingers_found += 1
                except: pass
            try:
                if lm[4].x < lm[2].x if lm[17].x > lm[2].x else lm[4].x > lm[2].x:
                    fingers_found += 1
            except: pass
            fingers_found = max(0, min(5, fingers_found))
            
            # --- CALCULATE Z-PROXIMITY (ESTIMATE) ---
            # Logic: Calculate distance between Wrist (0) and Middle MCP (9)
            # Closer camera = Larger distance in normalized coords
            try:
                x0, y0 = lm[0].x, lm[0].y
                x9, y9 = lm[9].x, lm[9].y
                # Euclidean distance
                dist = math.sqrt((x9-x0)**2 + (y9-y0)**2)
                
                # Normalize: Typical range is 0.1 (far) to 0.4 (very close)
                # Scale this to 0.0 - 1.0 for graph
                norm_prox = (dist - 0.1) * 3.5 # Tuning factor
                wrist_z_estimate = max(0.0, min(1.0, norm_prox))
            except: 
                wrist_z_estimate = 0.0

        # 2. Logic Updates
        self.history.append(fingers_found)
        chosen = self.history[-1]
        try:
            if len(self.history) == self.history.maxlen:
                counts = Counter(self.history)
                most_common = counts.most_common()
                if most_common:
                    chosen = max([v for v, c in most_common if c == most_common[0][1]])
        except: pass

        target_pct = fingers_to_percent(chosen)
        
        if len(self.history) == self.history.maxlen and target_pct != self.current_applied:
            try:
                set_mic_volume_percent(target_pct)
                self.current_applied = get_mic_volume_percent()
            except: pass

        self.last_observed = chosen
        muted = get_mic_is_muted()
        
        # 3. HUD Updates
        
        # A. ARC REACTOR (Updated Fix)
        try:
            vol_radians = (self.current_applied / 100.0) * (2 * math.pi)
            self.arc_bar.set_width(vol_radians)
            
            if self.current_applied < 50: col = '#00ffff'
            elif self.current_applied < 80: col = '#ff00ff'
            else: col = '#ff3333'
            
            self.arc_bar.set_color(col)
            self.text_vol.set_text(f"{int(self.current_applied)}%")
            self.canvas_arc.draw_idle()
        except: pass

        # B. Z-AXIS PROXIMITY UPDATE
        try:
            # Update bar height
            self.bar_prox.set_height(wrist_z_estimate)
            
            # Color Logic: Green(Far) -> Yellow -> Red(Close)
            if wrist_z_estimate < 0.5:
                self.bar_prox.set_color('#00ff00') # Green
            elif wrist_z_estimate < 0.8:
                self.bar_prox.set_color('#ffcc00') # Yellow/Orange
            else:
                self.bar_prox.set_color('#ff0000') # Critical Red
                
            self.canvas_prox.draw_idle()
        except: pass

        # 4. Display
        display_frame = self._overlay_text(frame.copy(), self.last_observed, self.current_applied, muted)
        img_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
        pil = Image.fromarray(img_rgb)
        try:
            lbl_w = self.video_label.winfo_width() or 1
            lbl_h = self.video_label.winfo_height() or 1
            pil = pil.resize((lbl_w, lbl_h), Image.LANCZOS)
        except: pass
        imgtk = ImageTk.PhotoImage(image=pil)
        self.video_label.imgtk = imgtk
        self.video_label.config(image=imgtk)

        # Status
        now = time.strftime("%H:%M:%S")
        status_txt = f"[{now}] | SYS: ONLINE | Fingers: {self.last_observed} | Vol: {self.current_applied}% | Mute: {muted} | Z-Depth: {wrist_z_estimate:.2f}"
        self.status_label.config(text=status_txt)

        self.root.after(15, self._update_frame)

    def _overlay_text(self, frame, fingers, volume, muted):
        h, w = frame.shape[:2]
        txt1 = f"Fingers: {fingers}"
        txt2 = f"Mic: {volume}%"
        mute_icon = "ðŸ”‡" if muted else "ðŸ”Š"
        font = cv2.FONT_HERSHEY_SIMPLEX
        scale1 = max(0.9, w / 640); scale2 = max(0.6, w / 900)
        thickness1 = 3; thickness2 = 2
        (t1_w, t1_h), _ = cv2.getTextSize(txt1, font, scale1, thickness1)
        (t2_w, t2_h), _ = cv2.getTextSize(txt2, font, scale2, thickness2)
        pad = 12
        box_w = max(t1_w, t2_w) + pad*4
        box_h = t1_h + t2_h + pad*3
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (10 + box_w, 10 + box_h), (6,6,6), -1)
        alpha = 0.6
        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)
        org1 = (10 + pad, 10 + pad + t1_h)
        cv2.putText(frame, txt1, org1, font, scale1, (0,220,180), thickness1+2, cv2.LINE_AA)
        cv2.putText(frame, txt1, org1, font, scale1, (255,255,255), thickness1, cv2.LINE_AA)
        org2 = (10 + pad, 10 + pad + t1_h + pad + t2_h)
        cv2.putText(frame, txt2, org2, font, scale2, (0,180,220), thickness2+2, cv2.LINE_AA)
        cv2.putText(frame, txt2, org2, font, scale2, (255,255,255), thickness2, cv2.LINE_AA)
        return frame

    def _on_close(self):
        self.running = False
        try: self.cap.release()
        except: pass
        try: self.hands.close()
        except: pass
        try: mc.close()
        except: pass
        try: os.unlink(child_path)
        except: pass
        try: self.root.destroy()
        except: pass
        sys.exit(0)

    def run(self):
        try: self.root.mainloop()
        finally: 
            try: mc.close()
            except: pass

if __name__ == "__main__":
    print("Initializing Infosys_GestureVolume...")
    app = App(stable_frames=6, win_w=WIN_W, win_h=WIN_H)
    app.run()
